{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHDP: RieszNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CumqS__UdZQj"
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1626014142199,
     "user": {
      "displayName": "Víctor Quintas Martínez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzDmne50Fc-Rgd6ii0jOAYJv9OzNuPlF4x0TOY2g=s64",
      "userId": "01033527572468555224"
     },
     "user_tz": 240
    },
    "id": "Tb0UNXId8Sbh"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.riesznet import RieszNet\n",
    "from utils.moments import ate_moment_fn\n",
    "from utils.ihdp_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_fn = ate_moment_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-OfQSQislV8"
   },
   "source": [
    "## MAE Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1030,
     "status": "ok",
     "timestamp": 1626014143226,
     "user": {
      "displayName": "Víctor Quintas Martínez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzDmne50Fc-Rgd6ii0jOAYJv9OzNuPlF4x0TOY2g=s64",
      "userId": "01033527572468555224"
     },
     "user_tz": 240
    },
    "id": "QKiyRUJTxMBe"
   },
   "outputs": [],
   "source": [
    "data_base_dir = \"./data/IHDP/sim_data\"\n",
    "simulation_files = sorted(glob.glob(\"{}/*.csv\".format(data_base_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytutDbXdY6ch"
   },
   "source": [
    "### Estimator Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1626014143228,
     "user": {
      "displayName": "Víctor Quintas Martínez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzDmne50Fc-Rgd6ii0jOAYJv9OzNuPlF4x0TOY2g=s64",
      "userId": "01033527572468555224"
     },
     "user_tz": 240
    },
    "id": "Xzye0tURZ4Mc",
    "outputId": "95a7f986-3019-44c9-c5ef-71aa1c147105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: False\n"
     ]
    }
   ],
   "source": [
    "drop_prob = 0.0  # dropout prob of dropout layers throughout notebook\n",
    "n_hidden = 100  # width of hidden layers throughout notebook\n",
    "\n",
    "# Training params\n",
    "learner_lr = 1e-5\n",
    "learner_l2 = 1e-3\n",
    "learner_l1 = 0.0\n",
    "n_epochs = 600\n",
    "earlystop_rounds = 40 # how many epochs to wait for an out-of-sample improvement\n",
    "earlystop_delta = 1e-4\n",
    "target_reg = 1.0\n",
    "riesz_weight = 0.1\n",
    "\n",
    "bs = 64\n",
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(\"GPU:\", torch.cuda.is_available())\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from itertools import combinations_with_replacement as combinations_w_r\n",
    "\n",
    "def _combinations(n_features, degree, interaction_only):\n",
    "        comb = (combinations if interaction_only else combinations_w_r)\n",
    "        return chain.from_iterable(comb(range(n_features), i)\n",
    "                                   for i in range(0, degree + 1))\n",
    "\n",
    "class Learner(nn.Module):\n",
    "\n",
    "    def __init__(self, n_t, n_hidden, p, degree, interaction_only=False):\n",
    "        super().__init__()\n",
    "        n_common = 200\n",
    "        self.monomials = list(_combinations(n_t, degree, interaction_only))\n",
    "        self.common = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU())\n",
    "        self.riesz_nn = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, 1))\n",
    "        self.riesz_poly = nn.Sequential(nn.Linear(len(self.monomials), 1))\n",
    "        self.reg_nn0 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "        self.reg_nn1 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "        self.reg_poly = nn.Sequential(nn.Linear(len(self.monomials), 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        poly = torch.cat([torch.prod(x[:, t], dim=1, keepdim=True)\n",
    "                          for t in self.monomials], dim=1)\n",
    "        feats = self.common(x)\n",
    "        riesz = self.riesz_nn(feats) + self.riesz_poly(poly)\n",
    "        reg = self.reg_nn0(feats) * (1 - x[:, [0]]) + self.reg_nn1(feats) * x[:, [0]] + self.reg_poly(poly)\n",
    "        return torch.cat([reg, riesz], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkato/Dropbox/ATEEstimation/ATEEstimation/utils/riesznet.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.model_dir,\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nsims = 1000\n",
    "np.random.seed(123)\n",
    "sim_ids = np.random.choice(len(simulation_files), nsims, replace=False)\n",
    "methods = ['dr', 'direct', 'ips']\n",
    "srr = {'dr' : True, 'direct' : False, 'ips' : True}\n",
    "\n",
    "true_ATEs = []\n",
    "results = []\n",
    "\n",
    "for it, sim in enumerate(sim_ids):\n",
    "    simulation_file = simulation_files[sim]\n",
    "    x = load_and_format_covariates(simulation_file, delimiter=' ')\n",
    "    t, y, y_cf, mu_0, mu_1 = load_other_stuff(simulation_file, delimiter=' ')\n",
    "    X = np.c_[t, x]\n",
    "    true_ATE = np.mean(mu_1 - mu_0)\n",
    "    true_ATEs.append(true_ATE)\n",
    "\n",
    "    y_scaler = StandardScaler(with_mean=True).fit(y)\n",
    "    y = y_scaler.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    learner = Learner(X_train.shape[1], n_hidden, drop_prob, 0, interaction_only=True)\n",
    "    agmm = RieszNet(learner, moment_fn)\n",
    "    # Fast training\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=2, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=1e-4, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=riesz_weight, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    # Fine tune\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=learner_lr, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=riesz_weight, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    \n",
    "    params = tuple(x * y_scaler.scale_[0] for method in methods\n",
    "                   for x in agmm.predict_avg_moment(X, y,  model='earlystop', method = method, srr = srr[method])) + (true_ATE, )\n",
    "                        \n",
    "    results.append(params)\n",
    "\n",
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub,\n",
    "                        'MAE': np.mean(np.abs(point - truth)),\n",
    "                        'std. err.': np.std(np.abs(point - truth)) / np.sqrt(nsims),\n",
    "                        }\n",
    "    print(\"{} : MAE = {:.3f} +/- {:.3f}\".format(method, res_dict[method]['MAE'], res_dict[method]['std. err.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr : MAE = 0.164 +/- 0.006\n",
      "direct : MAE = 0.159 +/- 0.003\n",
      "ips : MAE = 0.797 +/- 0.038\n"
     ]
    }
   ],
   "source": [
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub,\n",
    "                        'MAE': np.mean(np.abs(point - truth)),\n",
    "                        'std. err.': np.std(np.abs(point - truth)) / np.sqrt(nsims),\n",
    "                        }\n",
    "    print(\"{} : MAE = {:.3f} +/- {:.3f}\".format(method, res_dict[method]['MAE'], res_dict[method]['std. err.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of sklearn.utils.class_weight failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/class_weight.py\", line 13, in <module>\n",
      "    @validate_params(\n",
      "     ^^^^^^^^^^^^^^^^\n",
      "TypeError: validate_params() got an unexpected keyword argument 'prefer_skip_nested_validation'\n",
      "]\n",
      "[autoreload of threadpoolctl failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of sklearn.utils.fixes failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 29, in <module>\n",
      "    from .parallel import _get_threadpool_controller\n",
      "ImportError: cannot import name '_get_threadpool_controller' from 'sklearn.utils.parallel' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py)\n",
      "]\n",
      "[autoreload of sklearn.utils.validation failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 27, in <module>\n",
      "    from ..utils.fixes import ComplexWarning, _preserve_dia_indices_dtype\n",
      "ImportError: cannot import name 'ComplexWarning' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.utils failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 11, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 22, in <module>\n",
      "    @validate_params(\n",
      "     ^^^^^^^^^^^^^^^^\n",
      "TypeError: validate_params() got an unexpected keyword argument 'prefer_skip_nested_validation'\n",
      "]\n",
      "[autoreload of sklearn.utils._set_output failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 10, in <module>\n",
      "    from .fixes import _create_pandas_dataframe_from_non_pandas_container\n",
      "ImportError: cannot import name '_create_pandas_dataframe_from_non_pandas_container' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.utils._param_validation failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 2 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.base failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 26, in <module>\n",
      "    from .utils.fixes import _IS_32BIT\n",
      "ImportError: cannot import name '_IS_32BIT' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing._function_transformer failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py\", line 5, in <module>\n",
      "    from ..base import BaseEstimator, TransformerMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.utils.extmath failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: randomized_svd() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.utils.sparsefuncs failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/sparsefuncs.py\", line 12, in <module>\n",
      "    from ..utils.fixes import _sparse_min_max, _sparse_nan_min_max\n",
      "ImportError: cannot import name '_sparse_min_max' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of sklearn.preprocessing._encoders failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py\", line 12, in <module>\n",
      "    from ..base import BaseEstimator, OneToOneFeatureMixin, TransformerMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing._data failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\", line 18, in <module>\n",
      "    from ..base import (\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.utils.multiclass failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/multiclass.py\", line 15, in <module>\n",
      "    from ..utils.fixes import VisibleDeprecationWarning\n",
      "ImportError: cannot import name 'VisibleDeprecationWarning' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing._label failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py\", line 18, in <module>\n",
      "    from ..base import BaseEstimator, TransformerMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing._discretization failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py\", line 12, in <module>\n",
      "    from ..base import BaseEstimator, TransformerMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing._polynomial failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_polynomial.py\", line 15, in <module>\n",
      "    from ..base import BaseEstimator, TransformerMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.preprocessing failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/__init__.py\", line 28, in <module>\n",
      "    from ._target_encoder import TargetEncoder\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_target_encoder.py\", line 5, in <module>\n",
      "    from ..base import OneToOneFeatureMixin, _fit_context\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.model_selection._split failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: train_test_split() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.metrics._ranking failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_ranking.py\", line 41, in <module>\n",
      "    from ..utils.fixes import trapezoid\n",
      "ImportError: cannot import name 'trapezoid' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics._classification failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py\", line 59, in <module>\n",
      "    from ..utils.validation import (\n",
      "ImportError: cannot import name '_check_pos_label_consistency' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics.cluster._supervised failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: contingency_matrix() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.metrics._pairwise_distances_reduction._dispatcher failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 8, in <module>\n",
      "    from .._dist_metrics import (\n",
      "ImportError: cannot import name 'METRIC_MAPPING64' from 'sklearn.metrics._dist_metrics' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_dist_metrics.cpython-311-darwin.so)\n",
      "]\n",
      "[autoreload of sklearn.metrics._pairwise_distances_reduction failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py\", line 94, in <module>\n",
      "    from ._dispatcher import (\n",
      "ImportError: cannot import name 'ArgKminClassMode' from 'sklearn.metrics._pairwise_distances_reduction._dispatcher' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics.pairwise failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py\", line 47, in <module>\n",
      "    from ..utils.fixes import parse_version, sp_base_version\n",
      "ImportError: cannot import name 'sp_base_version' from 'sklearn.utils.fixes' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics.cluster._unsupervised failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: silhouette_score() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.metrics.cluster._bicluster failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: consensus_score() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.metrics._regression failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: mean_absolute_error() requires a code object with 0 free vars, not 3\n",
      "]\n",
      "[autoreload of sklearn.metrics._scorer failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py\", line 31, in <module>\n",
      "    from ..utils._response import _get_response_values\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 10, in <module>\n",
      "    from .validation import _check_response_method, check_is_fitted\n",
      "ImportError: cannot import name '_check_response_method' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics._plot.det_curve failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_plot/det_curve.py\", line 3, in <module>\n",
      "    from ...utils._plotting import _BinaryClassifierCurveDisplayMixin\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_plotting.py\", line 5, in <module>\n",
      "    from ._response import _get_response_values_binary\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 10, in <module>\n",
      "    from .validation import _check_response_method, check_is_fitted\n",
      "ImportError: cannot import name '_check_response_method' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of sklearn.metrics._plot.roc_curve failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_plot/roc_curve.py\", line 1, in <module>\n",
      "    from ...utils._plotting import _BinaryClassifierCurveDisplayMixin\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_plotting.py\", line 5, in <module>\n",
      "    from ._response import _get_response_values_binary\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 10, in <module>\n",
      "    from .validation import _check_response_method, check_is_fitted\n",
      "ImportError: cannot import name '_check_response_method' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics._plot.precision_recall_curve failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_plot/precision_recall_curve.py\", line 3, in <module>\n",
      "    from ...utils._plotting import _BinaryClassifierCurveDisplayMixin\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_plotting.py\", line 5, in <module>\n",
      "    from ._response import _get_response_values_binary\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 10, in <module>\n",
      "    from .validation import _check_response_method, check_is_fitted\n",
      "ImportError: cannot import name '_check_response_method' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.metrics failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/__init__.py\", line 4, in <module>\n",
      "    from ._classification import (\n",
      "ImportError: cannot import name 'd2_log_loss_score' from 'sklearn.metrics._classification' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py)\n",
      "]\n",
      "[autoreload of sklearn.model_selection._validation failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 48, in <module>\n",
      "    from ..utils.validation import _check_method_params, _num_samples\n",
      "ImportError: cannot import name '_check_method_params' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.model_selection._search failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py\", line 27, in <module>\n",
      "    from ..base import BaseEstimator, MetaEstimatorMixin, _fit_context, clone, is_classifier\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n",
      "[autoreload of sklearn.model_selection._plot failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_plot.py\", line 4, in <module>\n",
      "    from ..utils._plotting import _interval_max_min_ratio, _validate_score_name\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_plotting.py\", line 5, in <module>\n",
      "    from ._response import _get_response_values_binary\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_response.py\", line 10, in <module>\n",
      "    from .validation import _check_response_method, check_is_fitted\n",
      "ImportError: cannot import name '_check_response_method' from 'sklearn.utils.validation' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)\n",
      "]\n",
      "[autoreload of sklearn.model_selection failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 621, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/__init__.py\", line 5, in <module>\n",
      "    from ._classification_threshold import (\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_classification_threshold.py\", line 6, in <module>\n",
      "    from ..base import (\n",
      "ImportError: cannot import name '_fit_context' from 'sklearn.base' (/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py)\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m split_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(data, k)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, subset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(split_data):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "split_data = np.array_split(data, k)\n",
    "for i, subset in enumerate(split_data):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/IHDP/RieszNet/MAE'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "            \n",
    "dump(res_dict, path + '/IHDP_MAE_NN.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/IHDP/RieszNet/MAE'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "methods_str = [\"DR\", \"Direct\", \"IPS\"] \n",
    "\n",
    "with open(path + '/IHDP_MAE_NN.tex', \"w\") as f:\n",
    "    f.write(\"\\\\begin{tabular}{lc} \\n\" +\n",
    "            \"\\\\toprule \\n\" +\n",
    "            \"& MAE $\\\\pm$ std. err. \\\\\\\\ \\n\" +\n",
    "            \"\\\\midrule \\n\" +\n",
    "            \"\\\\multicolumn{2}{l}{\\\\textbf{Auto-DML:}} \\\\\\\\ \\n\")\n",
    "    \n",
    "    for i, method in enumerate(methods):\n",
    "        f.write(\" & \".join([methods_str[i], \"{:.3f} $\\\\pm$ {:.3f}\".format(res_dict[method]['MAE'], \n",
    "                                                                          res_dict[method]['std. err.'])]) + \" \\\\\\\\ \\n\")\n",
    "\n",
    "    f.write(\"\\\\multicolumn{2}{l}{\\\\textbf{Benchmark:}} \\\\\\\\\"\n",
    "            + \"\\n Dragonnet & 0.146 & 0.010 \\\\\\\\ \\n \\\\bottomrule \\n \\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = \"./data/IHDP/sim_data_redraw_T\"\n",
    "simulation_files = sorted(glob.glob(\"{}/*.csv\".format(data_base_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_fn(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "nsims = 100\n",
    "np.random.seed(123)\n",
    "sim_ids = np.random.choice(len(simulation_files), nsims, replace=False)\n",
    "methods = ['dr', 'direct', 'ips']\n",
    "srr = {'dr' : True, 'direct' : False, 'ips' : True}\n",
    "\n",
    "true_ATEs = []\n",
    "results = []\n",
    "\n",
    "for it, sim in enumerate(sim_ids):\n",
    "    simulation_file = simulation_files[sim]\n",
    "    x = load_and_format_covariates(simulation_file, delimiter=' ')\n",
    "    t, y, y_cf, mu_0, mu_1 = load_other_stuff(simulation_file, delimiter=' ')\n",
    "    X = np.c_[t, x]\n",
    "    true_ATE = np.mean(mu_1 - mu_0)\n",
    "    true_ATEs.append(true_ATE)\n",
    "\n",
    "    y_scaler = StandardScaler(with_mean=True).fit(y)\n",
    "    y = y_scaler.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    learner = Learner(X_train.shape[1], n_hidden, drop_prob, 0, interaction_only=True)\n",
    "    agmm = RieszNet(learner, moment_fn)\n",
    "    # Fast training\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=2, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=1e-4, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=riesz_weight, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    # Fine tune\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=learner_lr, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=riesz_weight, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    \n",
    "    params = tuple(x * y_scaler.scale_[0] for method in methods\n",
    "                   for x in agmm.predict_avg_moment(X, y,  model='earlystop', method = method, srr = srr[method])) + (true_ATE, )\n",
    "                        \n",
    "    results.append(params)\n",
    "                        \n",
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub,\n",
    "                        'cov': np.mean(np.logical_and(truth >= lb, truth <= ub)),\n",
    "                        'bias': np.mean(point - truth),\n",
    "                        'rmse': rmse_fn(point, truth)\n",
    "                        }\n",
    "    print(\"{} : bias = {:.3f}, rmse = {:.3f}, cov = {:.3f}\".format(method, res_dict[method]['bias'], res_dict[method]['rmse'], res_dict[method]['cov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/IHDP/RieszNet/coverage'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "dump(res_dict, path + '/IHDP_coverage_NN.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/IHDP/RieszNet/coverage'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "method_strs = [\"{}. Bias: {:.3f}, RMSE: {:.3f}, Coverage: {:.3f}\".format(method, d['bias'], d['rmse'], d['cov'])\n",
    "               for method, d in res_dict.items()]\n",
    "plt.title(\"\\n\".join(method_strs))\n",
    "for method, d in res_dict.items():\n",
    "    plt.hist(np.array(d['point']), alpha=.5, label=method)\n",
    "plt.axvline(x = np.mean(truth), label='true', color='red')\n",
    "plt.legend()\n",
    "plt.savefig(path + '/IHDP_coverage_NN.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of ‘end-to-end’ learning of shared representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RieszLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, n_t, p):\n",
    "        super().__init__()\n",
    "        n_common = 200\n",
    "        self.common = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU())\n",
    "        self.riesz_nn0 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, 1))\n",
    "        self.riesz_nn1 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.common(x)\n",
    "        riesz = self.riesz_nn0(feats) * (1 - x[:, [0]]) + self.riesz_nn1(feats) * x[:, [0]]\n",
    "        return torch.cat([riesz, feats], dim = 1)\n",
    "\n",
    "class RegLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, n_hidden, p):\n",
    "        super().__init__()\n",
    "        n_common = 200\n",
    "        self.reg_nn0 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "        self.reg_nn1 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = x[:, [0]]\n",
    "        riesz = x[:, [1]]\n",
    "        feats = x[:, 2:]\n",
    "        reg = self.reg_nn0(feats) * (1 - t) + self.reg_nn1(feats) * t\n",
    "        return torch.cat([reg, riesz], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = \"./data/IHDP/sim_data_redraw_T\"\n",
    "simulation_files = sorted(glob.glob(\"{}/*.csv\".format(data_base_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_fn(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "nsims = 100\n",
    "np.random.seed(123)\n",
    "sim_ids = np.random.choice(len(simulation_files), nsims, replace=False)\n",
    "methods = ['dr', 'direct', 'ips']\n",
    "srr = {'dr' : True, 'direct' : False, 'ips' : True}\n",
    "\n",
    "true_ATEs = []\n",
    "results = []\n",
    "\n",
    "for it, sim in enumerate(sim_ids):\n",
    "    simulation_file = simulation_files[sim]\n",
    "    x = load_and_format_covariates(simulation_file, delimiter=' ')\n",
    "    t, y, y_cf, mu_0, mu_1 = load_other_stuff(simulation_file, delimiter=' ')\n",
    "    X = np.c_[t, x]\n",
    "    true_ATE = np.mean(mu_1 - mu_0)\n",
    "    true_ATEs.append(true_ATE)\n",
    "\n",
    "    y_scaler = StandardScaler(with_mean=True).fit(y)\n",
    "    y = y_scaler.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Train Riesz\n",
    "    rrlearner = RieszLearner(X_train.shape[1], drop_prob)\n",
    "    rrnn = RieszNetRR(rrlearner, moment_fn)\n",
    "    ## Fast training\n",
    "    rrnn.fit(X_train, Xval=X_test,\n",
    "             earlystop_rounds=2, earlystop_delta=1e-2,\n",
    "             learner_lr=1e-1, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    ## Fine tune\n",
    "    rrnn.fit(X_train, Xval=X_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=1e-2,\n",
    "             learner_lr=1e-3, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "\n",
    "    # Train Reg\n",
    "    reglearner = RegLearner(n_hidden, drop_prob)\n",
    "    regnn = RieszNet(reglearner, moment_fn)\n",
    "    \n",
    "    inputs = np.hstack((X[:, [0]], rrnn.predict(X, model = 'earlystop')))\n",
    "    input_train = np.hstack((X_train[:, [0]], rrnn.predict(X_train, model = 'earlystop')))\n",
    "    input_test = np.hstack((X_test[:, [0]], rrnn.predict(X_test, model = 'earlystop')))\n",
    "    \n",
    "    ## Fast training\n",
    "    regnn.fit(input_train, y_train, input_test, yval=y_test,\n",
    "             earlystop_rounds=2, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=1e-4, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=0.0, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    # Fine tune\n",
    "    regnn.fit(input_train, y_train, input_test, yval=y_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=learner_lr, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=0.0, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    \n",
    "    params = tuple(x * y_scaler.scale_[0] for method in methods\n",
    "                   for x in regnn.predict_avg_moment(inputs, y,  model='earlystop', method = method, srr = srr[method])) + (true_ATE, )\n",
    "                        \n",
    "    results.append(params)\n",
    "                        \n",
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub, 'truth': truth,\n",
    "                        'cov': np.mean(np.logical_and(truth >= lb, truth <= ub)),\n",
    "                        'bias': np.mean(point - truth),\n",
    "                        'rmse': rmse_fn(point, truth)\n",
    "                        }\n",
    "    print(\"{} : bias = {:.3f}, rmse = {:.3f}, cov = {:.3f}\".format(method, res_dict[method]['bias'], res_dict[method]['rmse'], res_dict[method]['cov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./results/IHDP/RieszNet/ablation/IHDP_shared_ablation.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './results/IHDP/RieszNet/ablation'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "dump(res_dict, path + '/IHDP_shared_ablation.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of ‘end-to-end’ learning of TMLE adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr : bias = -0.058, rmse = 0.188, cov = 0.930\n",
      "direct : bias = -0.058, rmse = 0.188, cov = 0.670\n",
      "ips : bias = -0.171, rmse = 0.321, cov = 0.990\n"
     ]
    }
   ],
   "source": [
    "def rmse_fn(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "nsims = 100\n",
    "np.random.seed(123)\n",
    "sim_ids = np.random.choice(len(simulation_files), nsims, replace=False)\n",
    "methods = ['dr', 'direct', 'ips']\n",
    "\n",
    "true_ATEs = []\n",
    "results = []\n",
    "\n",
    "for it, sim in enumerate(sim_ids):\n",
    "    simulation_file = simulation_files[sim]\n",
    "    x = load_and_format_covariates(simulation_file, delimiter=' ')\n",
    "    t, y, y_cf, mu_0, mu_1 = load_other_stuff(simulation_file, delimiter=' ')\n",
    "    X = np.c_[t, x]\n",
    "    true_ATE = np.mean(mu_1 - mu_0)\n",
    "    true_ATEs.append(true_ATE)\n",
    "\n",
    "    y_scaler = StandardScaler(with_mean=True).fit(y)\n",
    "    y = y_scaler.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    learner = Learner(X_train.shape[1], n_hidden, drop_prob)\n",
    "    agmm = RieszNet(learner, moment_fn)\n",
    "    # Fast training\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=2, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=1e-4, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, target_reg=0.0,\n",
    "             riesz_weight=riesz_weight, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    # Fine tune\n",
    "    agmm.fit(X_train, y_train, Xval=X_test, yval=y_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=learner_lr, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, target_reg=0.0,\n",
    "             riesz_weight=riesz_weight, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    \n",
    "    params = tuple(x * y_scaler.scale_[0] for method in methods\n",
    "                   for x in agmm.predict_avg_moment(X, y,  model='earlystop', method = method, srr = False, postTMLE = True)) + (true_ATE, )\n",
    "                        \n",
    "    results.append(params)\n",
    "                        \n",
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub, 'truth': truth,\n",
    "                        'cov': np.mean(np.logical_and(truth >= lb, truth <= ub)),\n",
    "                        'bias': np.mean(point - truth),\n",
    "                        'rmse': rmse_fn(point, truth)\n",
    "                        }\n",
    "    print(\"{} : bias = {:.3f}, rmse = {:.3f}, cov = {:.3f}\".format(method, res_dict[method]['bias'], res_dict[method]['rmse'], res_dict[method]['cov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./results/IHDP/RieszNet/ablation/IHDP_postTMLE_ablation.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './results/IHDP/RieszNet/ablation'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "dump(res_dict, path + '/IHDP_postTMLE_ablation.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RieszLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, n_t, p):\n",
    "        super().__init__()\n",
    "        n_common = 200\n",
    "        self.common = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU())\n",
    "        self.riesz_nn0 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, 1))\n",
    "        self.riesz_nn1 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.common(x)\n",
    "        riesz = self.riesz_nn0(feats) * (1 - x[:, [0]]) + self.riesz_nn1(feats) * x[:, [0]]\n",
    "        return riesz\n",
    "\n",
    "class RegLearner(nn.Module):\n",
    "\n",
    "    def __init__(self, n_t, n_hidden, p):\n",
    "        super().__init__()\n",
    "        n_common = 200\n",
    "        self.common = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_common, n_common), nn.ELU())\n",
    "        self.reg_nn0 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "        self.reg_nn1 = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_common, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ELU(),\n",
    "                                    nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        X = x[:, 0:-1]\n",
    "        riesz = x[:, [-1]]\n",
    "        feats = self.common(X)\n",
    "        reg = self.reg_nn0(feats) * (1 - X[:, [0]]) + self.reg_nn1(feats) * X[:, [0]]\n",
    "        return torch.cat([reg, riesz], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr : bias = -0.176, rmse = 0.411, cov = 0.880\n",
      "direct : bias = -0.125, rmse = 0.190, cov = 0.710\n",
      "ips : bias = -0.034, rmse = 1.739, cov = 0.690\n"
     ]
    }
   ],
   "source": [
    "def rmse_fn(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "\n",
    "nsims = 100\n",
    "np.random.seed(123)\n",
    "sim_ids = np.random.choice(len(simulation_files), nsims, replace=False)\n",
    "methods = ['dr', 'direct', 'ips']\n",
    "srr = {'dr' : True, 'direct' : False, 'ips' : True}\n",
    "\n",
    "true_ATEs = []\n",
    "results = []\n",
    "\n",
    "for it, sim in enumerate(sim_ids):\n",
    "    simulation_file = simulation_files[sim]\n",
    "    x = load_and_format_covariates(simulation_file, delimiter=' ')\n",
    "    t, y, y_cf, mu_0, mu_1 = load_other_stuff(simulation_file, delimiter=' ')\n",
    "    X = np.c_[t, x]\n",
    "    true_ATE = np.mean(mu_1 - mu_0)\n",
    "    true_ATEs.append(true_ATE)\n",
    "\n",
    "    y_scaler = StandardScaler(with_mean=True).fit(y)\n",
    "    y = y_scaler.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Train Riesz\n",
    "    rrlearner = RieszLearner(X_train.shape[1], drop_prob)\n",
    "    rrnn = RieszNetRR(rrlearner, moment_fn)\n",
    "    ## Fast training\n",
    "    rrnn.fit(X_train, Xval=X_test,\n",
    "             earlystop_rounds=2, earlystop_delta=1e-2,\n",
    "             learner_lr=1e-1, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    ## Fine tune\n",
    "    rrnn.fit(X_train, Xval=X_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=1e-2,\n",
    "             learner_lr=1e-3, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "\n",
    "    # Train Reg\n",
    "    reglearner = RegLearner(X_train.shape[1], n_hidden, drop_prob)\n",
    "    regnn = RieszNet(reglearner, moment_fn)\n",
    "    \n",
    "    inputs = np.hstack((X, rrnn.predict(X, model = 'earlystop')))\n",
    "    input_train = np.hstack((X_train, rrnn.predict(X_train, model = 'earlystop')))\n",
    "    input_test = np.hstack((X_test, rrnn.predict(X_test, model = 'earlystop')))\n",
    "    \n",
    "    ## Fast training\n",
    "    regnn.fit(input_train, y_train, input_test, yval=y_test,\n",
    "             earlystop_rounds=2, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=1e-4, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=100, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=0.0, optimizer='adam',\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    # Fine tune\n",
    "    regnn.fit(input_train, y_train, input_test, yval=y_test,\n",
    "             earlystop_rounds=earlystop_rounds, earlystop_delta=earlystop_delta,\n",
    "             learner_lr=learner_lr, learner_l2=learner_l2, learner_l1=learner_l1,\n",
    "             n_epochs=600, bs=bs, target_reg=target_reg,\n",
    "             riesz_weight=0.0, optimizer='adam', warm_start=True,\n",
    "             model_dir=str(Path.home()), device=device, verbose=0)\n",
    "    \n",
    "    params = tuple(x * y_scaler.scale_[0] for method in methods\n",
    "                   for x in regnn.predict_avg_moment(inputs, y,  model='earlystop', method = method, srr = srr[method])) + (true_ATE, )\n",
    "                        \n",
    "    results.append(params)\n",
    "                        \n",
    "res = tuple(np.array(x) for x in zip(*results))\n",
    "truth = res[-1:]\n",
    "res_dict = {}\n",
    "for it, method in enumerate(methods):\n",
    "    point, lb, ub = res[it * 3: (it + 1)*3]\n",
    "    res_dict[method] = {'point': point, 'lb': lb, 'ub': ub, 'truth': truth,\n",
    "                        'cov': np.mean(np.logical_and(truth >= lb, truth <= ub)),\n",
    "                        'bias': np.mean(point - truth),\n",
    "                        'rmse': rmse_fn(point, truth)\n",
    "                        }\n",
    "    print(\"{} : bias = {:.3f}, rmse = {:.3f}, cov = {:.3f}\".format(method, res_dict[method]['bias'], res_dict[method]['rmse'], res_dict[method]['cov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./results/IHDP/RieszNet/ablation/IHDP_separateNNs_ablation.joblib']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './results/IHDP/RieszNet/ablation'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "dump(res_dict, path + '/IHDP_separateNNs_ablation.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './results/IHDP/RieszNet/ablation'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "methods_str = [\"DR\", \"Direct\", \"IPS\"] \n",
    "methods = ['direct', 'ips', 'dr']\n",
    "files = ['./results/IHDP/RieszNet/coverage/IHDP_coverage_NN.joblib',\n",
    "         path + '/IHDP_separateNNs_ablation.joblib',\n",
    "         path + '/IHDP_shared_ablation.joblib',\n",
    "         path + '/IHDP_postTMLE_ablation.joblib']\n",
    "names = [\"RieszNet\", \"Separate NNs\", \"No end-to-end\", \"TMLE post-proc.\"]\n",
    "\n",
    "with open(path + \"/ablation.tex\", \"w\") as f:\n",
    "    f.write(\"\\\\begin{tabular}{*{10}{r}} \\n\" +\n",
    "            \"\\\\toprule \\n\" +\n",
    "            \"& \\\\multicolumn{3}{c}{Direct} & \\\\multicolumn{3}{c}{IPS} & \\\\multicolumn{3}{c}{DR} \\\\\\\\ \\n\" +\n",
    "            \"\\\\cmidrule(lr){2-4} \\\\cmidrule(lr){5-7} \\\\cmidrule(lr){8-10} \\n\" +\n",
    "            \"&  Bias &  RMSE &  Cov. &  Bias &  RMSE &  Cov. &  Bias &  RMSE &  Cov. \\\\\\\\ \\n\" +\n",
    "            \"\\\\midrule \\n\")\n",
    "    \n",
    "    for i in range(4):\n",
    "        loaded = load(files[i])\n",
    "        f.write(names[i] + \" & \")    \n",
    "        f.write(\" & \".join([\"{:.3f}\".format(np.mean(loaded[method][x])) for method in methods\n",
    "                            for x in ['bias', 'rmse', 'cov']]) + \" \\\\\\\\ \\n\")\n",
    "\n",
    "    f.write(\"\\\\bottomrule \\n \\\\end{tabular}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NNRiesz_IHDP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
